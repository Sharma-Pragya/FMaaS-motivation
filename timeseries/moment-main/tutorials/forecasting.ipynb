{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Using MOMENT for Forecasting </h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "### 1. A Quick Introduction to Forecasting\n",
    "### 2. Loading MOMENT\n",
    "### 3. Inputs and Outputs\n",
    "### 4. Training the Forecasting Head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A Quick Introduction to Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series forecasting is another popular modeling task that involves predicting future values of a time series based on its historical patterns. For instance, in the context of stock market data, forecasting aims to estimate the future stock prices by analyzing past price movements and other relevant factors. In this tutorial, we will explore how to use MOMENT to tackle the time series forecasting in linearly probed setting. Mathematically, the time series forecasting problem can be defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: Given a time-series $T = [x_1, ..., x_L], \\ x_i \\in \\mathbb{R}^{C}$ of length $L$ with $C$ channels (sensors or variables), the forecasting problem is to predict the next $H$ time-steps $[x_{L+1}, \\dots, x_{L+H}]$. Depending on the length of the horizon, forecasting can be categorized as short or long-horizon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading MOMENT\n",
    "\n",
    "We will first install the MOMENT package, load some essential packages and the pre-trained model.\n",
    "\n",
    "MOMENT can be loaded in 4 modes: (1) `reconstruction`, (2) `embedding`, (3) `forecasting`, and (4) `classification`.\n",
    "\n",
    "In the `reconstruction` mode, MOMENT reconstructs input time series, potentially containing missing values. We can solve imputation and anomaly detection problems in this mode. This mode is suitable for solving imputation and anomaly detection tasks. During pre-training, MOMENT is trained to predict the missing values within uniformly randomly masked patches (disjoint sub-sequences) of the input time series, leveraging information from observed data in other patches. As a result, MOMENT comes equipped with a pre-trained reconstruction head, enabling it to address imputation and anomaly detection challenges in a zero-shot manner! Check out the `anomaly_detection.ipynb` and `imputation.ipynb` notebooks for more details!\n",
    "\n",
    "In the `embedding model`, MOMENT learns a $d$-dimensional embedding (e.g., $d=1024$ for `MOMENT-1-large`) for each input time series. These embeddings can be used for clustering and classification. MOMENT can learn embeddings in a zero-shot setting! Check out `representation_learning.ipynb` notebook for more details!\n",
    "\n",
    "The `forecasting` and `classification` modes are used for forecasting and classification tasks, respectively. In these modes, MOMENT learns representations which are subsequently mapped to the forecast horizon or the number of classes, using linear forecasting and classification heads. Both the forecasting and classification head are randomly initialized, and therefore must be fine-tuned before use. Check out the `forecasting.ipynb` notebook for more details!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hshastri_umass_edu/.conda/envs/moment/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# !pip install numpy pandas matplotlib tqdm\n",
    "# !pip install git+https://github.com/moment-timeseries-foundation-model/moment.git\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.cuda.amp\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "from momentfm.utils.utils import control_randomness\n",
    "from momentfm.data.informer_dataset import InformerDataset\n",
    "from momentfm.utils.forecasting_metrics import get_forecasting_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add your project root to sys.path (adjust the path below)\n",
    "project_root = '/work/pi_shenoy_umass_edu/hshastri/FMaaS-motivation/timeseries/moment-main'  # the folder containing 'momentfm'\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "os.chdir(f\"{project_root}/tutorials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from momentfm import MOMENTPipeline\n",
    "\n",
    "model = MOMENTPipeline.from_pretrained(\n",
    "    \"AutonLab/MOMENT-1-base\", \n",
    "    model_kwargs={\n",
    "        'task_name': 'forecasting',\n",
    "        'forecast_horizon': 192,\n",
    "        'head_dropout': 0.1,\n",
    "        'weight_decay': 0,\n",
    "        'freeze_encoder': True, # Freeze the patch embedding layer\n",
    "        'freeze_embedder': True, # Freeze the transformer encoder\n",
    "        'freeze_head': False, # The linear forecasting head must be trained\n",
    "    },\n",
    "    # local_files_only=True,  # Whether or not to only look at local files (i.e., do not try to download the model).\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOMENTPipeline(\n",
      "  (normalizer): RevIN()\n",
      "  (tokenizer): Patching()\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (value_embedding): Linear(in_features=8, out_features=768, bias=False)\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): ForecastingHead(\n",
      "    (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear): Linear(in_features=49152, out_features=192, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hshastri_umass_edu/.conda/envs/moment/lib/python3.10/site-packages/momentfm/models/moment.py:174: UserWarning: Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\n",
      "  warnings.warn(\"Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\")\n"
     ]
    }
   ],
   "source": [
    "model.init()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfrozen parameters:\n",
      "     head.linear.weight\n",
      "     head.linear.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Unfrozen parameters:\")\n",
    "for name, param in model.named_parameters():    \n",
    "    if param.requires_grad:\n",
    "        print('    ', name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inputs and Outputs\n",
    "\n",
    "Let's begin by performing a forward pass through MOMENT and examining its outputs!\n",
    "\n",
    "MOMENT takes 3 inputs:\n",
    "\n",
    "1. An input time series of length $T = 512$ timesteps and $C$ channels, and\n",
    "2. Two optional masks, both of length $T = 512$.\n",
    "    - The input mask is utilized to regulate the time steps or patches that the model should attend to. For instance, in the case of shorter time series, you may opt not to attend to padding. To implement this, you can provide an input mask with zeros in the padded locations.\n",
    "    - The second mask, referred to simply as mask, denotes masked or unobserved values. We employ mask tokens to replace all patches containing any masked time step (for further details, refer to Section 3.2 in our paper). MOMENT can attend to these mask tokens during reconstruction.\n",
    "    - By default, all time steps are observed and attended to.\n",
    "\n",
    "MOMENT returns a `TimeseriesOutputs` object. Since this is a forecasting task, it returns a `forecast` of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hshastri_umass_edu/.conda/envs/moment/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/hshastri_umass_edu/.conda/envs/moment/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeseriesOutputs(forecast=tensor([[[ 0.0073,  0.0073, -0.0759,  ...,  0.3001, -0.5155,  0.3226],\n",
      "         [-0.0783, -0.0910,  0.2409,  ...,  0.3752,  0.0048,  0.2299],\n",
      "         [-0.0736,  0.2091,  0.2233,  ...,  0.2090, -0.1216,  0.1754],\n",
      "         ...,\n",
      "         [ 0.1846, -0.0656,  0.2359,  ...,  0.1434,  0.0043,  0.0870],\n",
      "         [ 0.0395, -0.0288,  0.3249,  ...,  0.2857, -0.3078,  0.1197],\n",
      "         [-0.1384, -0.0780,  0.2092,  ...,  0.4440, -0.3038,  0.3062]],\n",
      "\n",
      "        [[-0.0744, -0.1123,  0.0059,  ...,  0.1199, -0.3702,  0.1967],\n",
      "         [ 0.2100,  0.1973,  0.1296,  ...,  0.2418,  0.0512,  0.1867],\n",
      "         [ 0.0633,  0.0059,  0.1366,  ...,  0.2121, -0.2733,  0.1286],\n",
      "         ...,\n",
      "         [ 0.0134, -0.1506,  0.0277,  ...,  0.3053, -0.1860,  0.2685],\n",
      "         [ 0.0655, -0.1485,  0.0655,  ...,  0.2651, -0.3251,  0.1819],\n",
      "         [ 0.1206,  0.0224,  0.4103,  ...,  0.3606, -0.1582,  0.2230]],\n",
      "\n",
      "        [[-0.1704, -0.2656,  0.0647,  ...,  0.0183, -0.2882,  0.0515],\n",
      "         [-0.0176, -0.3540,  0.1385,  ...,  0.2373, -0.2694,  0.2317],\n",
      "         [-0.0243, -0.0274,  0.2175,  ...,  0.2658, -0.1720,  0.0085],\n",
      "         ...,\n",
      "         [ 0.2092, -0.0534,  0.3786,  ...,  0.2764,  0.0740,  0.3111],\n",
      "         [-0.0944,  0.0324, -0.0124,  ...,  0.3939, -0.2710,  0.1860],\n",
      "         [ 0.1608,  0.0199,  0.0849,  ...,  0.1161, -0.2359,  0.0927]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1257,  0.0589,  0.2026,  ...,  0.4549, -0.0742,  0.2443],\n",
      "         [ 0.0040, -0.0050,  0.1238,  ...,  0.3706, -0.1101,  0.0854],\n",
      "         [ 0.2323, -0.1015,  0.0169,  ...,  0.0166, -0.2647,  0.2353],\n",
      "         ...,\n",
      "         [ 0.0231, -0.1326,  0.1160,  ...,  0.3102, -0.1906,  0.0432],\n",
      "         [-0.0053, -0.1590,  0.0285,  ...,  0.2905, -0.2571,  0.1453],\n",
      "         [ 0.0080, -0.0144,  0.0922,  ...,  0.4453, -0.1453,  0.1469]],\n",
      "\n",
      "        [[ 0.0440, -0.1699, -0.0137,  ...,  0.3074, -0.1286,  0.0711],\n",
      "         [ 0.0669, -0.0622,  0.2747,  ...,  0.1223, -0.1596, -0.0039],\n",
      "         [-0.0022, -0.0170,  0.0694,  ...,  0.3307,  0.0442,  0.2891],\n",
      "         ...,\n",
      "         [ 0.0159,  0.1379,  0.2456,  ...,  0.4152, -0.2199,  0.1682],\n",
      "         [ 0.0223, -0.1759,  0.0968,  ...,  0.5391, -0.2435,  0.2380],\n",
      "         [ 0.2402,  0.2091,  0.1978,  ...,  0.0740, -0.0991,  0.2663]],\n",
      "\n",
      "        [[-0.0378, -0.0355,  0.1670,  ...,  0.3194, -0.0273, -0.0273],\n",
      "         [-0.0718, -0.1635,  0.1598,  ...,  0.0488, -0.4762,  0.1697],\n",
      "         [-0.1323, -0.0367,  0.2283,  ...,  0.3587, -0.3530,  0.2812],\n",
      "         ...,\n",
      "         [ 0.0237, -0.0630, -0.0326,  ...,  0.2686, -0.0266,  0.1345],\n",
      "         [-0.0311, -0.1113,  0.1261,  ...,  0.1277, -0.1511, -0.0291],\n",
      "         [ 0.0510,  0.0090,  0.1094,  ...,  0.4500, -0.3076,  0.2024]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), anomaly_scores=None, logits=None, labels=None, input_mask=tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0'), pretrain_mask=None, reconstruction=None, embeddings=None, metadata=None, illegal_output=False)\n",
      "torch.Size([16, 7, 192])\n",
      "torch.Size([16, 1344])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import torch\n",
    "model.to(\"cuda\").float()\n",
    "# takes in tensor of shape [batchsize, n_channels, context_length]\n",
    "x = torch.randn(16, 7, 512)\n",
    "output = model(x_enc=x.float().to('cuda'))\n",
    "print(output)\n",
    "forecast=output.forecast\n",
    "print(forecast.shape)\n",
    "forecast= forecast.reshape(forecast.shape[0], -1)\n",
    "print(forecast.shape)  # Should be [batchsize, n_channels, forecast_horizon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Unsupervised Representation Learning using MOMENT\n",
    "\n",
    "In this setting, we use MOMENT to embed all training and testing time series. Then we train a statistical regressor (e.g. support vector machine) using the embeddings of the training time series as features and training labels. We will show that MOMENT can learn meaningful representations in a zero-shot setting, which can be used to train powerful statistical regressor. \n",
    "\n",
    "Let's embed the train and test datasets! We'll proceed as follows: \n",
    "First, we will write a simple function `get_embedding` which will iterate over the training and testing datasets, and embed each time series. Then we will use the `fit_svm` function to fit a support vector machine (SVM) model using these embeddings as features and training labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = InformerDataset(data_split=\"train\", random_seed=13, forecast_horizon=192)\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# test_dataset = InformerDataset(data_split=\"test\", random_seed=13, forecast_horizon=192)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for timeseries, forecast, input_mask in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "#     print(timeseries.shape, forecast.shape, input_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# def get_embedding(model, dataloader):\n",
    "#     embeddings, labels = [], []\n",
    "#     with torch.no_grad():\n",
    "#         for timeseries, forecast, input_mask in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "#             # Move the data to the GPU\n",
    "#             timeseries = timeseries.float().to('cuda')\n",
    "#             input_mask = input_mask.to('cuda')\n",
    "#             forecast = forecast.float().to('cuda')\n",
    "\n",
    "\n",
    "#             output = model(x_enc=timeseries, input_mask=input_mask)\n",
    "#             # print(output.forecast.shape())\n",
    "#             # embedding = output.embeddings\n",
    "#             forecast_result=output.forecast\n",
    "#             forecast_result=forecast_result.reshape(forecast_result.shape[0], -1)  # Flatten the forecast result\n",
    "#             forecast= forecast.reshape(forecast.shape[0], -1)\n",
    "#             embeddings.append(forecast_result.detach().cpu().numpy())\n",
    "#             labels.append(forecast.detach().cpu().numpy())        \n",
    "\n",
    "#     embeddings, labels = np.concatenate(embeddings), np.concatenate(labels)\n",
    "#     return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(\"cuda\").float()\n",
    "\n",
    "# train_embeddings, train_labels = get_embedding(model, train_dataloader)\n",
    "# test_embeddings, test_labels = get_embedding(model, test_dataloader)\n",
    "\n",
    "\n",
    "# print(train_embeddings.shape, train_labels.shape)\n",
    "# print(test_embeddings.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.multioutput import MultiOutputRegressor\n",
    "# from sklearn.svm import LinearSVR\n",
    "# svr = LinearSVR(max_iter=10000)\n",
    "# multi_svr = MultiOutputRegressor(svr)\n",
    "# multi_svr.fit(train_embeddings, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_train = multi_svr.predict(train_embeddings)\n",
    "# y_pred_test = multi_svr.predict(test_embeddings)\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# mae = mean_absolute_error(test_labels, y_pred_test)\n",
    "# print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the Forecasting Head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOMENT is pre-trained using a reconstruction head and a reconstruction head. To use MOMENT for forecasting, we replace the reconstruction head to a forecasting head. The forecasting head is a randomly initilized linear layer which maps MOMENT's embeddings to the forecasting horizon. \n",
    "\n",
    "**The forecasting head is randomly initialized, so it must be trained on your data.**\n",
    "\n",
    "Below, we show a quick example of how we can train the forecasting head. In these experiments, we will use Hourly Electricity Transformer Temperature (ETTh1) dataset introduced by [Zhou et al., 2020](https://arxiv.org/abs/2012.07436). Check out [ETDataset](https://github.com/zhouhaoyi/ETDataset) for more information! This dataset is widely use to benchmark long-horizon forecasting models. \n",
    "\n",
    "In this experiment, MOMENT will take multi-variate time series as input, and predict the next 192 time steps, i.e. the forecast horizon is set to 192. We will fine-tune the model using Mean Squarred Error (MSE), and report both MSE and the Mean Absolute Error (MAE) of the fine-tuned model. Since MOMENT is already pre-trained on millions of time series, we only need to fine-tune it for 1 epoch!\n",
    "\n",
    "We implemented a simple forecasting dataset class in `moment.data.informer_dataset`. `moment.utils.forecasting_metrics` contains implementations for MSE and MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Model Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2168254/1064119150.py:26: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "  0%|                                                                                           | 0/993 [00:00<?, ?it/s]/tmp/ipykernel_2168254/1064119150.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/hshastri_umass_edu/.conda/envs/moment/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/hshastri_umass_edu/.conda/envs/moment/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 993/993 [02:38<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train loss: 0.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/337 [00:00<?, ?it/s]/tmp/ipykernel_2168254/1064119150.py:80: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 337/337 [00:48<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test MSE: 0.414 | Test MAE: 0.428\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set random seeds for PyTorch, Numpy etc.\n",
    "control_randomness(seed=13) \n",
    "\n",
    "# Load data\n",
    "train_dataset = InformerDataset(data_split=\"train\", random_seed=13, forecast_horizon=192)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "test_dataset = InformerDataset(data_split=\"test\", random_seed=13, forecast_horizon=192)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cur_epoch = 0\n",
    "max_epoch = 1\n",
    "\n",
    "# Move the model to the GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Move the loss function to the GPU\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# Enable mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Create a OneCycleLR scheduler\n",
    "max_lr = 1e-4\n",
    "total_steps = len(train_loader) * max_epoch\n",
    "scheduler = OneCycleLR(optimizer, max_lr=max_lr, total_steps=total_steps, pct_start=0.3)\n",
    "\n",
    "# Gradient clipping value\n",
    "max_norm = 5.0\n",
    "\n",
    "while cur_epoch < max_epoch:\n",
    "    losses = []\n",
    "    for timeseries, forecast, input_mask in tqdm(train_loader, total=len(train_loader)):\n",
    "        # Move the data to the GPU\n",
    "        timeseries = timeseries.float().to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        forecast = forecast.float().to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(x_enc=timeseries, input_mask=input_mask)\n",
    "        \n",
    "        loss = criterion(output.forecast, forecast)\n",
    "\n",
    "        # Scales the loss for mixed precision training\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Clip gradients\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    losses = np.array(losses)\n",
    "    average_loss = np.average(losses)\n",
    "    print(f\"Epoch {cur_epoch}: Train loss: {average_loss:.3f}\")\n",
    "\n",
    "    # Step the learning rate scheduler\n",
    "    scheduler.step()\n",
    "    cur_epoch += 1\n",
    "    \n",
    "    # Evaluate the model on the test split\n",
    "    trues, preds, histories, losses = [], [], [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for timeseries, forecast, input_mask in tqdm(test_loader, total=len(test_loader)):\n",
    "        # Move the data to the GPU\n",
    "            timeseries = timeseries.float().to(device)\n",
    "            input_mask = input_mask.to(device)\n",
    "            forecast = forecast.float().to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(x_enc=timeseries, input_mask=input_mask)\n",
    "            loss = criterion(output.forecast, forecast)                \n",
    "            losses.append(loss.item())\n",
    "\n",
    "            trues.append(forecast.detach().cpu().numpy())\n",
    "            preds.append(output.forecast.detach().cpu().numpy())\n",
    "            histories.append(timeseries.detach().cpu().numpy())\n",
    "    \n",
    "    losses = np.array(losses)\n",
    "    average_loss = np.average(losses)\n",
    "    model.train()\n",
    "\n",
    "    trues = np.concatenate(trues, axis=0)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    histories = np.concatenate(histories, axis=0)\n",
    "    \n",
    "    metrics = get_forecasting_metrics(y=trues, y_hat=preds, reduction='mean')\n",
    "\n",
    "    print(f\"Epoch {cur_epoch}: Test MSE: {metrics.mse:.3f} | Test MAE: {metrics.mae:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Visualization\n",
    "\n",
    "Next, let's visualize the forecasts for a sample from the ETTh1 dataset and compare it with the ground truth forecast for the given time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming histories, trues, and preds are your lists containing the data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Extracting the first data point\u001b[39;00m\n\u001b[1;32m      6\u001b[0m channel_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m7\u001b[39m) \u001b[38;5;66;03m# There are 7 channels in this dataset\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/moment/lib/python3.10/site-packages/matplotlib/__init__.py:161\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrcsetup\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cycler  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/moment/lib/python3.10/site-packages/matplotlib/rcsetup.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackendFilter, backend_registry\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[0;32m~/.conda/envs/moment/lib/python3.10/site-packages/matplotlib/colors.py:52\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumbers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Real\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPngImagePlugin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PngInfo\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmpl\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming histories, trues, and preds are your lists containing the data\n",
    "# Extracting the first data point\n",
    "\n",
    "channel_idx = np.random.randint(0, 7) # There are 7 channels in this dataset\n",
    "time_index = np.random.randint(0, trues.shape[0]) \n",
    "\n",
    "history = histories[time_index, channel_idx, :] \n",
    "true = trues[time_index, channel_idx, :]\n",
    "pred = preds[time_index, channel_idx, :]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plotting the first time series from history\n",
    "plt.plot(range(len(history)), history, label='History (512 timesteps)', c='darkblue')\n",
    "\n",
    "# Plotting ground truth and prediction\n",
    "num_forecasts = len(true)\n",
    "\n",
    "offset = len(history)\n",
    "plt.plot(range(offset, offset + len(true)), true, label='Ground Truth (192 timesteps)', color='darkblue', linestyle='--', alpha=0.5)\n",
    "plt.plot(range(offset, offset + len(pred)), pred, label='Forecast (192 timesteps)', color='red', linestyle='--')\n",
    "\n",
    "plt.title(f\"ETTh1 (Hourly) -- (idx={time_index}, channel={channel_idx})\", fontsize=18)\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.ylabel('Value', fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Results Interpretation: MOMENT Performs Well for Forecasting in Limited Supervision Settings\n",
    "\n",
    "Here, we can see that MOMENT **trained for 1 epoch only, without any hyperparameter tuning**, can forecast time series well! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moment",
   "language": "python",
   "name": "moment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
