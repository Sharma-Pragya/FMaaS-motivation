{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ddd4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add your project root to sys.path (adjust the path below)\n",
    "project_root = '/work/pi_shenoy_umass_edu/hshastri/FMaaS-motivation/timeseries/amazon-chronos/src'  # the folder containing 'momentfm'\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f6b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from momentfm.data.classification_dataset import ClassificationDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from chronos import ChronosPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b2f6754",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/ECG5000_TRAIN.ts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mClassificationDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m ClassificationDataset(data_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_dataset)\n",
      "File \u001b[0;32m/work/pi_shenoy_umass_edu/hshastri/FMaaS-motivation/timeseries/amazon-chronos/src/momentfm/data/classification_dataset.py:22\u001b[0m, in \u001b[0;36mClassificationDataset.__init__\u001b[0;34m(self, data_split)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_split \u001b[38;5;241m=\u001b[39m data_split  \u001b[38;5;66;03m# 'train' or 'test'\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Read data\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/pi_shenoy_umass_edu/hshastri/FMaaS-motivation/timeseries/amazon-chronos/src/momentfm/data/classification_dataset.py:41\u001b[0m, in \u001b[0;36mClassificationDataset._read_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_tsfile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_file_path_and_name\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_labels \u001b[38;5;241m=\u001b[39m load_from_tsfile(\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_file_path_and_name\n\u001b[1;32m     46\u001b[0m     )\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_labels(\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_labels\n\u001b[1;32m     50\u001b[0m     )\n",
      "File \u001b[0;32m/work/pi_shenoy_umass_edu/hshastri/FMaaS-motivation/timeseries/amazon-chronos/src/momentfm/utils/data.py:46\u001b[0m, in \u001b[0;36mload_from_tsfile\u001b[0;34m(full_file_path_and_name, replace_missing_vals_with, return_meta_data, return_type)\u001b[0m\n\u001b[1;32m     44\u001b[0m     full_file_path_and_name \u001b[38;5;241m=\u001b[39m full_file_path_and_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.ts\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Open file\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfull_file_path_and_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# Read in headers\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     meta_data \u001b[38;5;241m=\u001b[39m _load_header_info(file)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# load into list of numpy\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/ECG5000_TRAIN.ts'"
     ]
    }
   ],
   "source": [
    "train_dataset = ClassificationDataset(data_split='train')\n",
    "test_dataset = ClassificationDataset(data_split='test')\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b8d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "idx = np.random.randint(0, len(train_dataset))\n",
    "heartbeat_start = np.argmax(train_dataset[idx][1])\n",
    "heartbeat = train_dataset[idx][0].squeeze()[heartbeat_start:]\n",
    "label = train_dataset[idx][2]\n",
    "plt.plot(heartbeat, c='darkblue')\n",
    "plt.title(f\"idx={idx} | label={label}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd66b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=False, drop_last=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-large\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c2f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, dataloader):\n",
    "    embeddings, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_masks, batch_labels in tqdm(dataloader, total=len(dataloader)):\n",
    "            batch_x = batch_x.to(\"cuda\").float()\n",
    "            batch_masks = batch_masks.to(\"cuda\")\n",
    "            embeddings, tokenizer_state = pipeline.embed(batch_x)\n",
    "            # output = model(x_enc=batch_x, input_mask=batch_masks) # [batch_size x d_model (=1024)]\n",
    "\n",
    "            # embedding = output.embeddings\n",
    "            embedding = output.embeddings.mean(dim=1)  # pooled to shape (batch_size, 1024)\n",
    "\n",
    "            embeddings.append(embedding.detach().cpu().numpy())\n",
    "            labels.append(batch_labels)        \n",
    "\n",
    "    embeddings, labels = np.concatenate(embeddings), np.concatenate(labels)\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85218bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda\").float()\n",
    "\n",
    "train_embeddings, train_labels = get_embedding(model, train_dataloader)\n",
    "test_embeddings, test_labels = get_embedding(model, test_dataloader)\n",
    "\n",
    "print(train_embeddings.shape, train_labels.shape)\n",
    "print(test_embeddings.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df98eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings_manifold = PCA(n_components=2).fit_transform(test_embeddings) \n",
    "\n",
    "plt.title(f\"ECG5000 Test Embeddings\", fontsize=20)\n",
    "plt.scatter(\n",
    "    test_embeddings_manifold[:, 0], \n",
    "    test_embeddings_manifold[:, 1],\n",
    "    c=test_labels.squeeze(),\n",
    "    cmap='magma'\n",
    ")\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.colorbar(\n",
    "    boundaries=np.arange(\n",
    "    min(test_labels),\n",
    "    max(test_labels)+1, 1)\n",
    ")\n",
    "plt.show()\n",
    "print(min(test_labels))\n",
    "print(max(test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
