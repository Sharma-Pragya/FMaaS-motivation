# THIS FILE IS AUTO-GENERATED by vlm_parser.py - DO NOT EDIT
# VLM profiling data in TSFM pipeline format.
# VLM models are backbones with decoder='none' (no sharing).

components={
    'Qwen/Qwen2.5-VL-3B-Instruct': {'mem': 8138.9375},
    'Qwen/Qwen2.5-VL-7B-Instruct': {'mem': 18206.9375},
    'allenai/Molmo-7B-D-0924': {'mem': 30928.9375},
    'llava-hf/llava-1.5-13b-hf': {'mem': 25730.9375},
    'llava-hf/llava-1.5-7b-hf': {'mem': 13738.9375},
    'llava-hf/llava-v1.6-vicuna-13b-hf': {'mem': 25730.9375},
    'meta-llama/Llama-3.2-11B-Vision-Instruct': {'mem': 21662.9375},
    'microsoft/Phi-3.5-vision-instruct': {'mem': 8460.9375},
    'openbmb/MiniCPM-V-2_6': {'mem': 15970.9375},
    'vikhyatk/moondream2': {'mem': 3962.9375},
    'none': {'mem': 0.0},
    'activity_recognition_Qwen/Qwen2.5-VL-3B-Instruct_none': {'mem': 30.0},
    'gesture_recognition_Qwen/Qwen2.5-VL-3B-Instruct_none': {'mem': 41.14},
    'image_classification_Qwen/Qwen2.5-VL-3B-Instruct_none': {'mem': 1446.606061},
    'object_detection_Qwen/Qwen2.5-VL-3B-Instruct_none': {'mem': 45.8},
    'ocr_Qwen/Qwen2.5-VL-3B-Instruct_none': {'mem': 26.0},
    'scene_classification_Qwen/Qwen2.5-VL-3B-Instruct_none': {'mem': 31.0},
    'traffic_classification_Qwen/Qwen2.5-VL-3B-Instruct_none': {'mem': 26.0},
    'vqa_Qwen/Qwen2.5-VL-3B-Instruct_none': {'mem': 41.92},
    'activity_recognition_Qwen/Qwen2.5-VL-7B-Instruct_none': {'mem': 39.142857},
    'crowd_counting_Qwen/Qwen2.5-VL-7B-Instruct_none': {'mem': 24.0},
    'gesture_recognition_Qwen/Qwen2.5-VL-7B-Instruct_none': {'mem': 57.4},
    'image_classification_Qwen/Qwen2.5-VL-7B-Instruct_none': {'mem': 1049.494949},
    'object_detection_Qwen/Qwen2.5-VL-7B-Instruct_none': {'mem': 67.56},
    'ocr_Qwen/Qwen2.5-VL-7B-Instruct_none': {'mem': 30.0},
    'scene_classification_Qwen/Qwen2.5-VL-7B-Instruct_none': {'mem': 4153.04},
    'traffic_classification_Qwen/Qwen2.5-VL-7B-Instruct_none': {'mem': 30.46},
    'vqa_Qwen/Qwen2.5-VL-7B-Instruct_none': {'mem': 62.08},
    'activity_recognition_allenai/Molmo-7B-D-0924_none': {'mem': 4290.0},
    'crowd_counting_allenai/Molmo-7B-D-0924_none': {'mem': 4214.0},
    'gesture_recognition_allenai/Molmo-7B-D-0924_none': {'mem': 4178.0},
    'image_classification_allenai/Molmo-7B-D-0924_none': {'mem': 4279.92},
    'object_detection_allenai/Molmo-7B-D-0924_none': {'mem': 4270.4},
    'ocr_allenai/Molmo-7B-D-0924_none': {'mem': 4290.0},
    'scene_classification_allenai/Molmo-7B-D-0924_none': {'mem': 4290.0},
    'traffic_classification_allenai/Molmo-7B-D-0924_none': {'mem': 4290.0},
    'vqa_allenai/Molmo-7B-D-0924_none': {'mem': 4190.0},
    'activity_recognition_llava-hf/llava-1.5-13b-hf_none': {'mem': 1054.0},
    'crowd_counting_llava-hf/llava-1.5-13b-hf_none': {'mem': 1054.0},
    'gesture_recognition_llava-hf/llava-1.5-13b-hf_none': {'mem': 1054.0},
    'image_classification_llava-hf/llava-1.5-13b-hf_none': {'mem': 1034.0},
    'object_detection_llava-hf/llava-1.5-13b-hf_none': {'mem': 1054.0},
    'ocr_llava-hf/llava-1.5-13b-hf_none': {'mem': 1034.0},
    'scene_classification_llava-hf/llava-1.5-13b-hf_none': {'mem': 1054.0},
    'traffic_classification_llava-hf/llava-1.5-13b-hf_none': {'mem': 1034.0},
    'vqa_llava-hf/llava-1.5-13b-hf_none': {'mem': 978.0},
    'activity_recognition_llava-hf/llava-1.5-7b-hf_none': {'mem': 734.0},
    'crowd_counting_llava-hf/llava-1.5-7b-hf_none': {'mem': 714.0},
    'gesture_recognition_llava-hf/llava-1.5-7b-hf_none': {'mem': 674.0},
    'image_classification_llava-hf/llava-1.5-7b-hf_none': {'mem': 674.0},
    'object_detection_llava-hf/llava-1.5-7b-hf_none': {'mem': 674.0},
    'ocr_llava-hf/llava-1.5-7b-hf_none': {'mem': 674.0},
    'scene_classification_llava-hf/llava-1.5-7b-hf_none': {'mem': 714.0},
    'traffic_classification_llava-hf/llava-1.5-7b-hf_none': {'mem': 674.0},
    'vqa_llava-hf/llava-1.5-7b-hf_none': {'mem': 680.0},
    'activity_recognition_llava-hf/llava-v1.6-vicuna-13b-hf_none': {'mem': 2532.0},
    'crowd_counting_llava-hf/llava-v1.6-vicuna-13b-hf_none': {'mem': 2916.0},
    'gesture_recognition_llava-hf/llava-v1.6-vicuna-13b-hf_none': {'mem': 3513.06},
    'image_classification_llava-hf/llava-v1.6-vicuna-13b-hf_none': {'mem': 4537.96},
    'object_detection_llava-hf/llava-v1.6-vicuna-13b-hf_none': {'mem': 4343.42},
    'ocr_llava-hf/llava-v1.6-vicuna-13b-hf_none': {'mem': 1882.0},
    'scene_classification_llava-hf/llava-v1.6-vicuna-13b-hf_none': {'mem': 4084.46},
    'traffic_classification_llava-hf/llava-v1.6-vicuna-13b-hf_none': {'mem': 2023.72},
    'vqa_llava-hf/llava-v1.6-vicuna-13b-hf_none': {'mem': 4160.0},
    'activity_recognition_meta-llama/Llama-3.2-11B-Vision-Instruct_none': {'mem': 36.0},
    'crowd_counting_meta-llama/Llama-3.2-11B-Vision-Instruct_none': {'mem': 34.0},
    'gesture_recognition_meta-llama/Llama-3.2-11B-Vision-Instruct_none': {'mem': 36.0},
    'image_classification_meta-llama/Llama-3.2-11B-Vision-Instruct_none': {'mem': 32.0},
    'object_detection_meta-llama/Llama-3.2-11B-Vision-Instruct_none': {'mem': 30.18},
    'ocr_meta-llama/Llama-3.2-11B-Vision-Instruct_none': {'mem': 30.0},
    'scene_classification_meta-llama/Llama-3.2-11B-Vision-Instruct_none': {'mem': 36.0},
    'traffic_classification_meta-llama/Llama-3.2-11B-Vision-Instruct_none': {'mem': 32.0},
    'vqa_meta-llama/Llama-3.2-11B-Vision-Instruct_none': {'mem': 31.58},
    'activity_recognition_microsoft/Phi-3.5-vision-instruct_none': {'mem': 150.0},
    'crowd_counting_microsoft/Phi-3.5-vision-instruct_none': {'mem': 148.0},
    'gesture_recognition_microsoft/Phi-3.5-vision-instruct_none': {'mem': 148.0},
    'image_classification_microsoft/Phi-3.5-vision-instruct_none': {'mem': 244.0},
    'object_detection_microsoft/Phi-3.5-vision-instruct_none': {'mem': 244.0},
    'ocr_microsoft/Phi-3.5-vision-instruct_none': {'mem': 146.0},
    'scene_classification_microsoft/Phi-3.5-vision-instruct_none': {'mem': 148.0},
    'traffic_classification_microsoft/Phi-3.5-vision-instruct_none': {'mem': 146.0},
    'vqa_microsoft/Phi-3.5-vision-instruct_none': {'mem': 143.02},
    'activity_recognition_openbmb/MiniCPM-V-2_6_none': {'mem': 140.0},
    'crowd_counting_openbmb/MiniCPM-V-2_6_none': {'mem': 777.92},
    'gesture_recognition_openbmb/MiniCPM-V-2_6_none': {'mem': 333.58},
    'image_classification_openbmb/MiniCPM-V-2_6_none': {'mem': 733.64},
    'object_detection_openbmb/MiniCPM-V-2_6_none': {'mem': 343.94},
    'ocr_openbmb/MiniCPM-V-2_6_none': {'mem': 140.0},
    'scene_classification_openbmb/MiniCPM-V-2_6_none': {'mem': 801.76},
    'traffic_classification_openbmb/MiniCPM-V-2_6_none': {'mem': 140.0},
    'vqa_openbmb/MiniCPM-V-2_6_none': {'mem': 345.96},
    'activity_recognition_vikhyatk/moondream2_none': {'mem': 608.0},
    'crowd_counting_vikhyatk/moondream2_none': {'mem': 780.0},
    'gesture_recognition_vikhyatk/moondream2_none': {'mem': 902.76},
    'image_classification_vikhyatk/moondream2_none': {'mem': 900.6},
    'object_detection_vikhyatk/moondream2_none': {'mem': 905.76},
    'ocr_vikhyatk/moondream2_none': {'mem': 608.0},
    'scene_classification_vikhyatk/moondream2_none': {'mem': 1016.68},
    'traffic_classification_vikhyatk/moondream2_none': {'mem': 608.0},
    'vqa_vikhyatk/moondream2_none': {'mem': 804.0},
}

pipelines={
    'p1': {'backbone': 'Qwen/Qwen2.5-VL-3B-Instruct', 'decoder': 'none', 'task': 'activity_recognition'},
    'p2': {'backbone': 'Qwen/Qwen2.5-VL-3B-Instruct', 'decoder': 'none', 'task': 'gesture_recognition'},
    'p3': {'backbone': 'Qwen/Qwen2.5-VL-3B-Instruct', 'decoder': 'none', 'task': 'image_classification'},
    'p4': {'backbone': 'Qwen/Qwen2.5-VL-3B-Instruct', 'decoder': 'none', 'task': 'object_detection'},
    'p5': {'backbone': 'Qwen/Qwen2.5-VL-3B-Instruct', 'decoder': 'none', 'task': 'ocr'},
    'p6': {'backbone': 'Qwen/Qwen2.5-VL-3B-Instruct', 'decoder': 'none', 'task': 'scene_classification'},
    'p7': {'backbone': 'Qwen/Qwen2.5-VL-3B-Instruct', 'decoder': 'none', 'task': 'traffic_classification'},
    'p8': {'backbone': 'Qwen/Qwen2.5-VL-3B-Instruct', 'decoder': 'none', 'task': 'vqa'},
    'p9': {'backbone': 'Qwen/Qwen2.5-VL-7B-Instruct', 'decoder': 'none', 'task': 'activity_recognition'},
    'p10': {'backbone': 'Qwen/Qwen2.5-VL-7B-Instruct', 'decoder': 'none', 'task': 'crowd_counting'},
    'p11': {'backbone': 'Qwen/Qwen2.5-VL-7B-Instruct', 'decoder': 'none', 'task': 'gesture_recognition'},
    'p12': {'backbone': 'Qwen/Qwen2.5-VL-7B-Instruct', 'decoder': 'none', 'task': 'image_classification'},
    'p13': {'backbone': 'Qwen/Qwen2.5-VL-7B-Instruct', 'decoder': 'none', 'task': 'object_detection'},
    'p14': {'backbone': 'Qwen/Qwen2.5-VL-7B-Instruct', 'decoder': 'none', 'task': 'ocr'},
    'p15': {'backbone': 'Qwen/Qwen2.5-VL-7B-Instruct', 'decoder': 'none', 'task': 'scene_classification'},
    'p16': {'backbone': 'Qwen/Qwen2.5-VL-7B-Instruct', 'decoder': 'none', 'task': 'traffic_classification'},
    'p17': {'backbone': 'Qwen/Qwen2.5-VL-7B-Instruct', 'decoder': 'none', 'task': 'vqa'},
    'p18': {'backbone': 'allenai/Molmo-7B-D-0924', 'decoder': 'none', 'task': 'activity_recognition'},
    'p19': {'backbone': 'allenai/Molmo-7B-D-0924', 'decoder': 'none', 'task': 'crowd_counting'},
    'p20': {'backbone': 'allenai/Molmo-7B-D-0924', 'decoder': 'none', 'task': 'gesture_recognition'},
    'p21': {'backbone': 'allenai/Molmo-7B-D-0924', 'decoder': 'none', 'task': 'image_classification'},
    'p22': {'backbone': 'allenai/Molmo-7B-D-0924', 'decoder': 'none', 'task': 'object_detection'},
    'p23': {'backbone': 'allenai/Molmo-7B-D-0924', 'decoder': 'none', 'task': 'ocr'},
    'p24': {'backbone': 'allenai/Molmo-7B-D-0924', 'decoder': 'none', 'task': 'scene_classification'},
    'p25': {'backbone': 'allenai/Molmo-7B-D-0924', 'decoder': 'none', 'task': 'traffic_classification'},
    'p26': {'backbone': 'allenai/Molmo-7B-D-0924', 'decoder': 'none', 'task': 'vqa'},
    'p27': {'backbone': 'llava-hf/llava-1.5-13b-hf', 'decoder': 'none', 'task': 'activity_recognition'},
    'p28': {'backbone': 'llava-hf/llava-1.5-13b-hf', 'decoder': 'none', 'task': 'crowd_counting'},
    'p29': {'backbone': 'llava-hf/llava-1.5-13b-hf', 'decoder': 'none', 'task': 'gesture_recognition'},
    'p30': {'backbone': 'llava-hf/llava-1.5-13b-hf', 'decoder': 'none', 'task': 'image_classification'},
    'p31': {'backbone': 'llava-hf/llava-1.5-13b-hf', 'decoder': 'none', 'task': 'object_detection'},
    'p32': {'backbone': 'llava-hf/llava-1.5-13b-hf', 'decoder': 'none', 'task': 'ocr'},
    'p33': {'backbone': 'llava-hf/llava-1.5-13b-hf', 'decoder': 'none', 'task': 'scene_classification'},
    'p34': {'backbone': 'llava-hf/llava-1.5-13b-hf', 'decoder': 'none', 'task': 'traffic_classification'},
    'p35': {'backbone': 'llava-hf/llava-1.5-13b-hf', 'decoder': 'none', 'task': 'vqa'},
    'p36': {'backbone': 'llava-hf/llava-1.5-7b-hf', 'decoder': 'none', 'task': 'activity_recognition'},
    'p37': {'backbone': 'llava-hf/llava-1.5-7b-hf', 'decoder': 'none', 'task': 'crowd_counting'},
    'p38': {'backbone': 'llava-hf/llava-1.5-7b-hf', 'decoder': 'none', 'task': 'gesture_recognition'},
    'p39': {'backbone': 'llava-hf/llava-1.5-7b-hf', 'decoder': 'none', 'task': 'image_classification'},
    'p40': {'backbone': 'llava-hf/llava-1.5-7b-hf', 'decoder': 'none', 'task': 'object_detection'},
    'p41': {'backbone': 'llava-hf/llava-1.5-7b-hf', 'decoder': 'none', 'task': 'ocr'},
    'p42': {'backbone': 'llava-hf/llava-1.5-7b-hf', 'decoder': 'none', 'task': 'scene_classification'},
    'p43': {'backbone': 'llava-hf/llava-1.5-7b-hf', 'decoder': 'none', 'task': 'traffic_classification'},
    'p44': {'backbone': 'llava-hf/llava-1.5-7b-hf', 'decoder': 'none', 'task': 'vqa'},
    'p45': {'backbone': 'llava-hf/llava-v1.6-vicuna-13b-hf', 'decoder': 'none', 'task': 'activity_recognition'},
    'p46': {'backbone': 'llava-hf/llava-v1.6-vicuna-13b-hf', 'decoder': 'none', 'task': 'crowd_counting'},
    'p47': {'backbone': 'llava-hf/llava-v1.6-vicuna-13b-hf', 'decoder': 'none', 'task': 'gesture_recognition'},
    'p48': {'backbone': 'llava-hf/llava-v1.6-vicuna-13b-hf', 'decoder': 'none', 'task': 'image_classification'},
    'p49': {'backbone': 'llava-hf/llava-v1.6-vicuna-13b-hf', 'decoder': 'none', 'task': 'object_detection'},
    'p50': {'backbone': 'llava-hf/llava-v1.6-vicuna-13b-hf', 'decoder': 'none', 'task': 'ocr'},
    'p51': {'backbone': 'llava-hf/llava-v1.6-vicuna-13b-hf', 'decoder': 'none', 'task': 'scene_classification'},
    'p52': {'backbone': 'llava-hf/llava-v1.6-vicuna-13b-hf', 'decoder': 'none', 'task': 'traffic_classification'},
    'p53': {'backbone': 'llava-hf/llava-v1.6-vicuna-13b-hf', 'decoder': 'none', 'task': 'vqa'},
    'p54': {'backbone': 'meta-llama/Llama-3.2-11B-Vision-Instruct', 'decoder': 'none', 'task': 'activity_recognition'},
    'p55': {'backbone': 'meta-llama/Llama-3.2-11B-Vision-Instruct', 'decoder': 'none', 'task': 'crowd_counting'},
    'p56': {'backbone': 'meta-llama/Llama-3.2-11B-Vision-Instruct', 'decoder': 'none', 'task': 'gesture_recognition'},
    'p57': {'backbone': 'meta-llama/Llama-3.2-11B-Vision-Instruct', 'decoder': 'none', 'task': 'image_classification'},
    'p58': {'backbone': 'meta-llama/Llama-3.2-11B-Vision-Instruct', 'decoder': 'none', 'task': 'object_detection'},
    'p59': {'backbone': 'meta-llama/Llama-3.2-11B-Vision-Instruct', 'decoder': 'none', 'task': 'ocr'},
    'p60': {'backbone': 'meta-llama/Llama-3.2-11B-Vision-Instruct', 'decoder': 'none', 'task': 'scene_classification'},
    'p61': {'backbone': 'meta-llama/Llama-3.2-11B-Vision-Instruct', 'decoder': 'none', 'task': 'traffic_classification'},
    'p62': {'backbone': 'meta-llama/Llama-3.2-11B-Vision-Instruct', 'decoder': 'none', 'task': 'vqa'},
    'p63': {'backbone': 'microsoft/Phi-3.5-vision-instruct', 'decoder': 'none', 'task': 'activity_recognition'},
    'p64': {'backbone': 'microsoft/Phi-3.5-vision-instruct', 'decoder': 'none', 'task': 'crowd_counting'},
    'p65': {'backbone': 'microsoft/Phi-3.5-vision-instruct', 'decoder': 'none', 'task': 'gesture_recognition'},
    'p66': {'backbone': 'microsoft/Phi-3.5-vision-instruct', 'decoder': 'none', 'task': 'image_classification'},
    'p67': {'backbone': 'microsoft/Phi-3.5-vision-instruct', 'decoder': 'none', 'task': 'object_detection'},
    'p68': {'backbone': 'microsoft/Phi-3.5-vision-instruct', 'decoder': 'none', 'task': 'ocr'},
    'p69': {'backbone': 'microsoft/Phi-3.5-vision-instruct', 'decoder': 'none', 'task': 'scene_classification'},
    'p70': {'backbone': 'microsoft/Phi-3.5-vision-instruct', 'decoder': 'none', 'task': 'traffic_classification'},
    'p71': {'backbone': 'microsoft/Phi-3.5-vision-instruct', 'decoder': 'none', 'task': 'vqa'},
    'p72': {'backbone': 'openbmb/MiniCPM-V-2_6', 'decoder': 'none', 'task': 'activity_recognition'},
    'p73': {'backbone': 'openbmb/MiniCPM-V-2_6', 'decoder': 'none', 'task': 'crowd_counting'},
    'p74': {'backbone': 'openbmb/MiniCPM-V-2_6', 'decoder': 'none', 'task': 'gesture_recognition'},
    'p75': {'backbone': 'openbmb/MiniCPM-V-2_6', 'decoder': 'none', 'task': 'image_classification'},
    'p76': {'backbone': 'openbmb/MiniCPM-V-2_6', 'decoder': 'none', 'task': 'object_detection'},
    'p77': {'backbone': 'openbmb/MiniCPM-V-2_6', 'decoder': 'none', 'task': 'ocr'},
    'p78': {'backbone': 'openbmb/MiniCPM-V-2_6', 'decoder': 'none', 'task': 'scene_classification'},
    'p79': {'backbone': 'openbmb/MiniCPM-V-2_6', 'decoder': 'none', 'task': 'traffic_classification'},
    'p80': {'backbone': 'openbmb/MiniCPM-V-2_6', 'decoder': 'none', 'task': 'vqa'},
    'p81': {'backbone': 'vikhyatk/moondream2', 'decoder': 'none', 'task': 'activity_recognition'},
    'p82': {'backbone': 'vikhyatk/moondream2', 'decoder': 'none', 'task': 'crowd_counting'},
    'p83': {'backbone': 'vikhyatk/moondream2', 'decoder': 'none', 'task': 'gesture_recognition'},
    'p84': {'backbone': 'vikhyatk/moondream2', 'decoder': 'none', 'task': 'image_classification'},
    'p85': {'backbone': 'vikhyatk/moondream2', 'decoder': 'none', 'task': 'object_detection'},
    'p86': {'backbone': 'vikhyatk/moondream2', 'decoder': 'none', 'task': 'ocr'},
    'p87': {'backbone': 'vikhyatk/moondream2', 'decoder': 'none', 'task': 'scene_classification'},
    'p88': {'backbone': 'vikhyatk/moondream2', 'decoder': 'none', 'task': 'traffic_classification'},
    'p89': {'backbone': 'vikhyatk/moondream2', 'decoder': 'none', 'task': 'vqa'},
}

latency={
    'p1': {'A6000': 183.02117},
    'p2': {'A6000': 103.39941},
    'p3': {'A6000': 123.26137},
    'p4': {'A6000': 126.10464},
    'p5': {'A6000': 55.0751},
    'p6': {'A6000': 446.40923},
    'p7': {'A6000': 70.46076},
    'p8': {'A6000': 122.53479},
    'p9': {'A6000': 222.44859},
    'p10': {'A6000': 852.30112},
    'p11': {'A6000': 146.53578},
    'p12': {'A6000': 183.35364},
    'p13': {'A6000': 188.73204},
    'p14': {'A6000': 76.05841},
    'p15': {'A6000': 524.0631},
    'p16': {'A6000': 103.71278},
    'p17': {'A6000': 176.76375},
    'p18': {'A6000': 640.68801},
    'p19': {'A6000': 1726.92156},
    'p20': {'A6000': 947.8048},
    'p21': {'A6000': 866.29672},
    'p22': {'A6000': 1071.78944},
    'p23': {'A6000': 545.37637},
    'p24': {'A6000': 1112.14874},
    'p25': {'A6000': 594.11815},
    'p26': {'A6000': 1074.07884},
    'p27': {'A6000': 426.99892},
    'p28': {'A6000': 334.56425},
    'p29': {'A6000': 294.94005},
    'p30': {'A6000': 292.20698},
    'p31': {'A6000': 307.63692},
    'p32': {'A6000': 306.07351},
    'p33': {'A6000': 306.67924},
    'p34': {'A6000': 307.55361},
    'p35': {'A6000': 281.12378},
    'p36': {'A6000': 271.77416},
    'p37': {'A6000': 196.04492},
    'p38': {'A6000': 164.82998},
    'p39': {'A6000': 162.87166},
    'p40': {'A6000': 176.21408},
    'p41': {'A6000': 173.84082},
    'p42': {'A6000': 181.60877},
    'p43': {'A6000': 175.30921},
    'p44': {'A6000': 162.62469},
    'p45': {'A6000': 670.87589},
    'p46': {'A6000': 752.9154},
    'p47': {'A6000': 857.89347},
    'p48': {'A6000': 824.54046},
    'p49': {'A6000': 833.90176},
    'p50': {'A6000': 496.31429},
    'p51': {'A6000': 695.75153},
    'p52': {'A6000': 495.32704},
    'p53': {'A6000': 836.27109},
    'p54': {'A6000': 272.78645},
    'p55': {'A6000': 510.56164},
    'p56': {'A6000': 254.81696},
    'p57': {'A6000': 425.34489},
    'p58': {'A6000': 89.77559},
    'p59': {'A6000': 68.90939},
    'p60': {'A6000': 234.12714},
    'p61': {'A6000': 234.25808},
    'p62': {'A6000': 115.7751},
    'p63': {'A6000': 591.83969},
    'p64': {'A6000': 594.18189},
    'p65': {'A6000': 448.89879},
    'p66': {'A6000': 460.91268},
    'p67': {'A6000': 483.2706},
    'p68': {'A6000': 500.87859},
    'p69': {'A6000': 443.84887},
    'p70': {'A6000': 501.07059},
    'p71': {'A6000': 438.95672},
    'p72': {'A6000': 446.10197},
    'p73': {'A6000': 397.32977},
    'p74': {'A6000': 129.99368},
    'p75': {'A6000': 164.4589},
    'p76': {'A6000': 171.33641},
    'p77': {'A6000': 99.48487},
    'p78': {'A6000': 239.99526},
    'p79': {'A6000': 123.12953},
    'p80': {'A6000': 164.84656},
    'p81': {'A6000': 144.5928},
    'p82': {'A6000': 156.99052},
    'p83': {'A6000': 150.25447},
    'p84': {'A6000': 115.82895},
    'p85': {'A6000': 144.66537},
    'p86': {'A6000': 83.35627},
    'p87': {'A6000': 137.58677},
    'p88': {'A6000': 95.73006},
    'p89': {'A6000': 148.62317},
}

metric={
    'p1': 0.0,
    'p2': 0.56,
    'p3': 0.35,
    'p4': 0.71,
    'p5': 0.72,
    'p6': 0.5,
    'p7': 0.92,
    'p8': 0.74,
    'p9': 0.0,
    'p10': 0.17,
    'p11': 0.75,
    'p12': 0.39,
    'p13': 0.71,
    'p14': 0.92,
    'p15': 0.45,
    'p16': 0.93,
    'p17': 0.71,
    'p18': 0.0,
    'p19': 0.12,
    'p20': 0.04,
    'p21': 0.33,
    'p22': 0.6,
    'p23': 0.65,
    'p24': 0.29,
    'p25': 0.0,
    'p26': 0.55,
    'p27': 0.0,
    'p28': 0.27,
    'p29': 0.74,
    'p30': 0.27,
    'p31': 0.62,
    'p32': 0.79,
    'p33': 0.37,
    'p34': 0.99,
    'p35': 0.65,
    'p36': 0.0,
    'p37': 0.63,
    'p38': 0.79,
    'p39': 0.22,
    'p40': 0.66,
    'p41': 0.87,
    'p42': 0.31,
    'p43': 0.99,
    'p44': 0.66,
    'p45': 0.0,
    'p46': 0.15,
    'p47': 0.56,
    'p48': 0.29,
    'p49': 0.65,
    'p50': 0.77,
    'p51': 0.34,
    'p52': 1.0,
    'p53': 0.72,
    'p54': 0.0,
    'p55': 0.0,
    'p56': 0.0,
    'p57': 0.0,
    'p58': 0.17,
    'p59': 0.02,
    'p60': 0.0,
    'p61': 0.0,
    'p62': 0.29,
    'p63': 0.0,
    'p64': 0.21,
    'p65': 0.55,
    'p66': 0.33,
    'p67': 0.61,
    'p68': 0.75,
    'p69': 0.28,
    'p70': 0.89,
    'p71': 0.64,
    'p72': 0.0,
    'p73': 0.28,
    'p74': 0.68,
    'p75': 0.3,
    'p76': 0.67,
    'p77': 0.82,
    'p78': 0.46,
    'p79': 0.95,
    'p80': 0.76,
    'p81': 0.0,
    'p82': 0.15,
    'p83': 0.13,
    'p84': 0.41,
    'p85': 0.59,
    'p86': 0.78,
    'p87': 0.36,
    'p88': 0.87,
    'p89': 0.7,
}

